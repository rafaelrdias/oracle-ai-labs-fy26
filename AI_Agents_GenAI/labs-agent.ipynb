{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf2f57b-2ac5-43e3-a55e-0247b0baf365",
   "metadata": {},
   "source": [
    "# Lab - Agents  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286ee33-911f-4efc-849f-aa50f3562a72",
   "metadata": {},
   "source": [
    "### Dependencias necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e370bea5-c70f-45cc-8fc0-6e522675f6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain_community\n",
    "!pip install langchain_openai\n",
    "!pip install langgraph\n",
    "!pip install langchain_core\n",
    "!pip install langchain_oci\n",
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a113ff-cab2-4edc-99e4-ef0a547077e8",
   "metadata": {},
   "source": [
    "### Configuração do modelo costumizado\n",
    "-- Esse modelo foi deployado pelo Rafael Dias no Labs de Data Science, você deve reproduzir o laboratório para substituir o endpoint da llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2536471-baad-43fe-893d-e9f6887e32d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ads \n",
    "import oci\n",
    "from langchain_community.llms import OCIModelDeploymentVLLM\n",
    "\n",
    "ads.set_auth(\"resource_principal\")\n",
    "\n",
    "llm = OCIModelDeploymentVLLM(\n",
    "    model=\"odsc-llm\",\n",
    "    endpoint=\"https://modeldeployment.sa-saopaulo-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.sa-saopaulo-1.amaaaaaad6nji3aavxgsev3sce2yzas46jjosxyb5acc22p6rolzvcgannrq/predict\",\n",
    "    model_kwargs={\n",
    "        'max_tokens': 500,\n",
    "        'temperature': 0.3,\n",
    "        'top_k': 50,\n",
    "        'top_p': 0.99,\n",
    "        'frequency_penalty': 0,\n",
    "        'presence_penalty': 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb44faa4-a689-48f5-beec-5dc6c541d63b",
   "metadata": {},
   "source": [
    "#### Caso você não queira fazer o deploy de um modelo, pode usar um modelo on-demand, do exemplo abaixo\n",
    "-- Troque o compartment_id para que funcione"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37a8bb27-673d-427e-a8ef-b36a81a611f3",
   "metadata": {},
   "source": [
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..aaaaaaaael2x4x2flfdgrteymct63e73zghik5gbyzd2zsww7ihzkfldpdza\"\n",
    "AUTH_TYPE = \"API_KEY\"\n",
    "CONFIG_PROFILE = \"DEFAULT\"\n",
    "endpoint = \"https://inference.generativeai.sa-saopaulo-1.oci.oraclecloud.com\"\n",
    "\n",
    "llm = ChatOCIGenAI(\n",
    "    model_id=\"ocid1.generativeaimodel.oc1.sa-saopaulo-1.amaaaaaask7dceyaj4gd4x4c3cwpege5r3mb62b2wocgq2xxgrwia5z72j2a\",\n",
    "    service_endpoint=endpoint,\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    "    provider=\"meta\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.8,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"top_p\": 0.8\n",
    "    },\n",
    "    auth_type=AUTH_TYPE,\n",
    "    auth_profile=CONFIG_PROFILE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f14163-81db-45e8-b5c2-152b5910a9a8",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70537e91-0cd8-4683-b21d-bfc5b4bf8797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.agents import AgentType, initialize_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63b9e4-83e8-4956-99c0-7caf028191c1",
   "metadata": {},
   "source": [
    "### Definindo Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7f6726-d9a3-439a-b0d3-aa1469978bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_tool = DuckDuckGoSearchResults()\n",
    "\n",
    "search = Tool(\n",
    "    name=\"search\",\n",
    "    func=search_tool,\n",
    "    description=\"Research different queries (always in Portuguese pt-br) to search for informations on web.\"\n",
    ")\n",
    "\n",
    "tools =[search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42556d03-4fe1-467c-baf6-cd92fc14a2cc",
   "metadata": {},
   "source": [
    "### Prompt para o agente \n",
    "Deve incluir {tools} {chat_history} {input} que vão ser internamente variaveis do agente para o fluxo da conversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d00dde-9282-4128-943c-cfb9be5a8046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Você é um assistente, que tem as seguintes tools:\n",
    "{tools}\n",
    "\n",
    "Seja objetivo e politico para responder a seguinte pergunta do usuário:\n",
    "{input}\n",
    "\n",
    "Pense, use as ferramentas que podem te ajudar, pense novamente, repita quantas vezes for necessário e responda o usuário.\n",
    "A resposta final SEMPRE DEVE ser em português, direcionada ao usuário, que responda ao que ele pediu com informações úteis.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae73574-13c6-4959-80af-c9b16839f291",
   "metadata": {},
   "source": [
    "### Criação do agente e junção das partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80a32ef-d331-4f9d-8a5e-8455d65275c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, ConversationalChatAgent\n",
    "\n",
    "# Criação do elemento tipo agente com base em um template\n",
    "agent = ZeroShotAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912921c-266d-424c-9476-2c90022919cf",
   "metadata": {},
   "source": [
    "### Chamada do agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "88a4bf84-77c2-412b-9243-496fa042b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  qual a previsão de SP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os próximos dias em São Paulo tem um clima seco, com temperaturas mais amigáveis durante o período da tarde. A precipitação está indo diminuindo.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input in ['quit', 'exit', 'sair']:\n",
    "        break\n",
    "    else:\n",
    "        messages = agent_chain.invoke({\"input\": f\"{user_input}\"})\n",
    "        print(messages['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b70a23-e83e-4958-870e-4310ff2ff80c",
   "metadata": {},
   "source": [
    "### Adicionando histórico\n",
    "-- Para isso vamos trocar para ConversationalChatAgent e adicionar os elementos mandatórios no prompt {tools}, {chat_history} e {input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bbdec60-10cf-4c90-9a8a-c1c048cd5b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Você é um assistente, que tem as seguintes tools:\n",
    "{tools}\n",
    "\n",
    "Histórico da conversa:\n",
    "{chat_history}\n",
    "\n",
    "Seja objetivo e politico para responder a seguinte pergunta do usuário:\n",
    "{input}\n",
    "\n",
    "Pense, use as ferramentas que podem te ajudar, pense novamente, repita quantas vezes for necessário e responda o usuário.\n",
    "IMPORTANTE: A resposta final SEMPRE DEVE ser em português!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "739a7830-c146-430d-a8e2-045d71ed8c59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent\n",
    "\n",
    "# Criação do elemento tipo agente com base em um template\n",
    "agent = ConversationalChatAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# configuração do histórico\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\"\n",
    ")\n",
    "\n",
    "# Criação do agente: junção de tudo\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bba41f9c-ad1c-4f3e-b158-d6976f2dc85d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  previsão do tempo em SP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m no dia 19/08/2023\n",
      "- response: ```json\n",
      "{\n",
      "    \"action\": \"search\",\n",
      "    \"action_input\": \"previsão do tempo em São Paulo no dia 19/08/2023\"\n",
      "}\n",
      "```\n",
      "\n",
      "explanation: Here is the markdown code snippet formatted in JSON schema for using a tool to look up information on web regarding the user's question:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"search\",\n",
      "    \"action_input\": \"previsão do tempo em São Paulo no dia 19/08/2023\"\n",
      "}\n",
      "```\n",
      "Note that I have translated \"SP\" to its full form, \"São Paulo,\" as the user's instructions specified searching in Portuguese (pt-br). However, if you prefer to keep it abbreviated for consistency with your original example or other contextual needs, feel free to adjust accordingly.\n",
      "\n",
      "In this case, I have used \"search\" as the action because we need to look up information on web regarding the weather forecast in São Paulo on August 19th, 2023.\n",
      "\n",
      "The `action_input` is a query that will be used for searching online resources about the weather forecast in São Paulo on the specified date.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3msnippet: Previsão do Tempo em São Paulo - SP, os próximos 14 dias, com as últimas previsões meteorológicos. Informações sobre precipitação, umidade, vento, temperatura...., title: Previsão do tempo São Paulo SP. 14 dias - tempo.com | Meteored, link: https://www.tempo.com/sao-paulo.htm, snippet: Saiba qual é a previsão do tempo para os próximos 15 dias em São Paulo - SP. Confira se haverá previsão de chuva para São Paulo - SP na Climatempo, o melhor site de meteorologia do Brasil., title: Previsão do tempo para os próximos 15 dias em São Paulo 2v6a2a SP ..., link: https://climatempo-br.noticiasderoraima.com/previsao-do-tempo/15-dias/cidade/558/saopaulo-sp, snippet: PREVISÃO DO TEMPO PARA ALGUMAS CIDADES DO ESTADO DE SP, title: IPMet - Boletim do Tempo, link: https://www.ipmetradar.com.br/2tempo.php, snippet: A previsão do tempo é de sol. Na manhã 24.1°C, à tarde 32.3°C e durante a noite 26.2°C. A temperatura mínima para São Paulo é de 19.3°C, e a máxima de 32.4°C., title: Clima para amanhã em São Paulo-SP: previsão do tempo desta segunda ..., link: https://diariodonordeste.verdesmares.com.br/ultima-hora/pais/clima-para-amanha-em-sao-paulo-sp-previsao-do-tempo-desta-segunda-feira-19x2f08-1.3547706\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "<|assistant|> ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Based on the information obtained from various sources, the weather forecast for São Paulo on August 19th, 2023 indicates a mix of sun and clouds with temperatures ranging between 24°C to 32.4°C during the day.\"\n",
      "}\n",
      "```\n",
      "I have synthesized information from multiple sources provided in your input into a coherent response regarding the weather forecast for São Paulo on August 19th, 2023.\n",
      "\n",
      "Note: The exact details may vary based on real-time updates and data accuracy. It's always recommended to check official meteorological websites closer to the date for the most accurate information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the information obtained from various sources, the weather forecast for São Paulo on August 19th, 2023 indicates a mix of sun and clouds with temperatures ranging between 24°C to 32.4°C during the day.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input in ['quit', 'exit', 'q']:\n",
    "        break\n",
    "    else:\n",
    "        messages = agent_chain.invoke({\"input\": f\"{user_input}\"})\n",
    "        print(messages['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
